\section{Distributed Graph Databases}
\label{sec:distr-graph-datab}

A distributed graph database employs a shared-nothing architecture, partitioning a graph among loosely cooperating servers.
Graph partitioning is non-trivial and a common approach is to use a $k$-balanced edge cut \cite{Huang2016}.
The objective of such an approach is to minimize the proportion of edges that span partitions and also to balance the distribution of vertices to partitions.
Fig \ref{dist-graph} depicts a graph database partitioned across 3 servers, $S_i, i = 1, 2$ and $3$.\footnote{Typically, each partition would be replicated for fault tolerance and availability, but these issues are beyond the scope of this paper.}

Intra-partition and inter-partition edges are respectively referred to as \textit{local edges}  and  \textit{distributed edges} (shown using dashed lines in Fig \ref{dist-graph}).
The proportion of distributed edges is not negligible and can range from 25-75\% \cite{Huang2016}.

\input{figures/dist-graph}

Adjacency lists can now contain edge pointers to vertices on remote servers.
Guaranteeing reciprocal consistency for distributed edges is challenging, especially when an existing BASE database is used for storage and is then adapted with a query language expressed in terms of edges and vertices along with some gluecode to bind that interface to the underlying database.
Opting for this design appears to be a good choice: it offers the application programmer the modeling convenience of graphs together with the operational characteristics of the underlying BASE database.

However, a major problem with this design option is the lack of transactional semantics from the underlying BASE databases.
The latter seldom provide guarantees for multi-operation, multi-object transactions that span partitions. Without concurrency control across partitions, concurrent updates of distributed edges can interleave and violate reciprocal consistency.\footnote{The concurrency control primitives provided by BASE databases are typically sufficient to ensure reciprocal consistency for local edges.}
Our earlier work showed that undermining reciprocal consistency in distributed edges can lead to irreversible corruption of the distributed database itself and the corruption rate can be worryingly high (\cite{Ezhilchelvan2018}, \cite{Webber2019}).
Origins of reciprocal inconsistency in distributed edges are explained in Section \ref{sec:db-corruption}.

\input{figures/conflict-scenarios}
